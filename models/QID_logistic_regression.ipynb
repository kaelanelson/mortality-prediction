{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_log_reg(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "\n",
    "    train_pred = clf.predict_proba(X_train)\n",
    "    test_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    return train_score,test_score,train_pred,test_pred\n",
    "\n",
    "def plot_log_preds(df, X_train, X_test, train_preds, test_preds, x_col, y_col):\n",
    "    plt.scatter(df[x_cols], df[y_col], label='True Vals')\n",
    "    plt.scatter(X_train[x_cols], train_preds[:,1], label='Train Pred')\n",
    "    plt.scatter(X_test[x_cols], test_preds[:,1], label='Test Pred')\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(\"Simple Logistic Regression Predictions\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling on five states with most deaths (found through EDA): \n",
    "California, Florida, New York, Texas, Pensylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"medicare_aggregated_qid_2011_2012.csv\")\n",
    "\n",
    "states = ['CA', 'FL', 'NY', 'TX', 'PA']\n",
    "state_df = df[df.statecode.isin(states)]\n",
    "\n",
    "# sample random subsample\n",
    "df_sub = state_df.sample(n=1000000)\n",
    "\n",
    "df_sub = map_statecode(df_sub)\n",
    "\n",
    "# remove columns not for modeling\n",
    "df_sub2 = df_sub.drop(columns=['qid', 'pm25_ensemble', 'death'])\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sub2.drop(columns=['dead']), df_sub2.dead, test_size=0.3, random_state=42)\n",
    "\n",
    "# standardize\n",
    "non_binary_predictors = ['age','latitude','longitude', 'pm25_nn', \n",
    "       'ozone', 'poverty', 'popdensity', 'medianhousevalue', 'pct_blk',\n",
    "       'medhouseholdincome', 'pct_owner_occ', 'hispanic', 'education',\n",
    "       'smoke_rate', 'mean_bmi', 'tmmx', 'rmax', 'pr']\n",
    "\n",
    "X_train_standardized, X_test_standardized = standardize(non_binary_predictors,X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression and Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split into train and test set\n",
    "train_df, test_df = train_test_split(state_df, test_size=0.2, random_state=42)\n",
    "\n",
    "num_bootstraps = 300\n",
    "num_sample = 1000000\n",
    "\n",
    "model_coef = []\n",
    "for i in range(num_bootstraps):\n",
    "    # resample\n",
    "    sub = train_df.sample(n=num_sample, replace=True)\n",
    "    # map statecode\n",
    "    sub2 = map_statecode(sub)\n",
    "    # split into x and y\n",
    "    x_boot_train = sub2.drop(columns=['dead'])\n",
    "    y_boot_train = sub2.dead\n",
    "    #standardize x\n",
    "    x_boot_standardized = standardize(x_boot_train)\n",
    "    # fit model\n",
    "    model = LogisticRegression().fit(x_boot_standardized[['pm25_nn','ozone','tmmx','rmax']], y_boot_train)\n",
    "    # save coefficients\n",
    "    model_coef.append(model.coef_) \n",
    "    \n",
    "model_coef = np.array(model_coef).reshape((num_bootstraps,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_betas(model_coef):\n",
    "    fig, ax = plt.subplots(2,2, figsize = (18,10))\n",
    "    ax = ax.ravel()\n",
    "    for i in range(4):\n",
    "        betavals = model_coef[:,i]\n",
    "        betavals.sort()\n",
    "        x1 = np.percentile(betavals,2.5)\n",
    "        x2 = np.percentile(betavals,97.5)\n",
    "        x = np.linspace(x1,x2,500)\n",
    "        counts, bins = np.histogram(betavals)\n",
    "        y = counts.max()\n",
    "        ax[i].hist(model_coef[:,i],bins =10, color=\"#FF7E79\",alpha=0.3,edgecolor='black', linewidth=1)\n",
    "        ax[i].fill_between(x,y, color = '#007D66',alpha=0.2)\n",
    "        # Prettify\n",
    "        ax[i].set_ylim(0,27)\n",
    "        ax[i].set_ylabel(f'Distribution of beta {i+1}',fontsize=18)\n",
    "        ax[i].set_xlabel(f'Value of beta {i+1}',fontsize=18)\n",
    "    #plt.xticks(fontsize=20)\n",
    "    fig.suptitle(f'95 % confidence interval of coefficients', fontsize = 24)\n",
    "    sns.despine()\n",
    "\n",
    "plot_betas(model_coef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
