{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# https://johaupt.github.io/python/parallel%20processing/cross-validation/multiprocessing_cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(non_binary_predictors, X_train, X_test=None):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train[non_binary_predictors])\n",
    "    \n",
    "    # if x_test is passed in, or just x_train \n",
    "    if X_test is not None:\n",
    "        X_train[non_binary_predictors] = scaler.transform(X_train[non_binary_predictors])\n",
    "        X_test[non_binary_predictors] = scaler.transform(X_test[non_binary_predictors])\n",
    "        return X_train, X_test\n",
    "    else:\n",
    "        X_train[non_binary_predictors] = scaler.transform(X_train[non_binary_predictors])\n",
    "        return X_train  \n",
    "\n",
    "def split_and_standardize(df, x_cols, y_col, non_binary_preds, interact_cols=None):\n",
    "    # separate into X and y\n",
    "    X = df[x_cols]\n",
    "    y = df[y_col]\n",
    "    \n",
    "    if interact_cols != None:\n",
    "        for i,c in enumerate(interact_cols.keys()):\n",
    "            X[c] = X[interact_cols[c][0]]*X[interact_cols[c][1]]\n",
    "    \n",
    "    # split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=109)\n",
    "    \n",
    "    # standardize\n",
    "    X_train_standardized, X_test_standardized = standardize(non_binary_preds, X_train,X_test)\n",
    "    \n",
    "    return X_train_standardized, y_train, X_test_standardized, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('zip_train_v2.csv')\n",
    "df_test= pd.read_csv('zip_test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = ['sex', 'age','poverty', 'popdensity', 'medianhousevalue', \n",
    "        'medhouseholdincome', 'pct_owner_occ','education',\n",
    "        'smoke_rate', 'mean_bmi', 'rmax', 'pr', 'race_0', 'race_1', 'race_2',\n",
    "        'race_3', 'race_4', 'race_5', 'race_6','ICU_DAY', 'CCI_DAY', 'LOS', \n",
    "        'Parkinson_pdx2dx_25','Alzheimer_pdx2dx_25', 'Dementia_pdx2dx_25', 'CHF_pdx2dx_25',\n",
    "       'AMI_pdx2dx_25', 'COPD_pdx2dx_25', 'DM_pdx2dx_25', 'Stroke_pdx2dx_25',\n",
    "       'CVD_pdx2dx_25', 'Ischemic_stroke_pdx2dx_25','Hemo_Stroke_pdx2dx_25',\n",
    "        'neo_140_149', 'neo_150_159', 'neo_160_165',\n",
    "       'neo_170_176', 'neo_179_189', 'neo_190_199', 'neo_200_209',\n",
    "       'neo_210_229', 'neo_230_234', 'neo_235_238', 'neo_239','pm25_summer_4y_avg', \n",
    "       'pm25_winter_4y_avg', 'pm25_fall_4y_avg', 'pm25_spring_4y_avg','ozone_summer_4y_avg', 'ozone_winter_4y_avg', \n",
    "       'ozone_fall_4y_avg', 'ozone_spring_4y_avg','no2_summer_4y_avg', 'no2_winter_4y_avg', 'no2_fall_4y_avg', \n",
    "       'no2_spring_4y_avg', 'summer_tmmx_4y_avg','summer_rmax_4y_avg', 'winter_tmmx_4y_avg', 'winter_rmax_4y_avg']\n",
    "\n",
    "y_col = 'death'\n",
    "# non_binary_preds = x_col\n",
    "\n",
    "# split into train and test and standardize\n",
    "# X_train_standardized, y_train, X_test_standardized, y_test = split_and_standardize(df_train, x_col, y_col, non_binary_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_library = {}\n",
    "# for n in [30,40,50,60]:\n",
    "#     for d in range(10,14):\n",
    "#         model_library['rf_'+str(n)+'_'+str(d)] = RandomForestRegressor(n_estimators = n, max_depth = d, max_features='sqrt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_models(X,y, split):\n",
    "    # split\n",
    "    X_train, y_train = X.iloc[list(split[0]),:], y.iloc[list(split[0])]\n",
    "    X_test, y_test =  X.iloc[list(split[1]),:], y.iloc[list(split[1])]\n",
    "    \n",
    "    # model library\n",
    "    model_library = {}\n",
    "    for n in [60]:\n",
    "        for d in [15,16,17,18]:\n",
    "            model_library['rf_'+str(n)+'_'+str(d)] = RandomForestRegressor(n_estimators = n, max_depth = d, max_features='sqrt')\n",
    "                                                 \n",
    "    results_train = {}\n",
    "    results_test = {}\n",
    "    for model_name, model in model_library.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        results_train[model_name] = model.score(X_train, y_train)\n",
    "        results_test[model_name] = model.score(X_test, y_test)\n",
    "    return (pd.DataFrame(results_train, index=['rf_train_scores']),pd.DataFrame(results_test, index=['rf_test_scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/tools/lib/anaconda/3-5.2.0/lib/python3.6/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "folds = list(splitter.split(df_train[x_col], df_train[y_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_models(df_train[x_col], df_train[y_col], split=folds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(5)\n",
    "# mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def rf_result(x):\n",
    "    results.append(x)\n",
    "    \n",
    "for fold in folds:\n",
    "    pool.apply_async(benchmark_models, args=(df_train[x_col], df_train[y_col], fold), callback=rf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = pd.concat([results[i][0] for i in range(len(folds))], axis=0, sort=True)\n",
    "result_test = pd.concat([results[i][1] for i in range(len(folds))], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train.mean(axis=0), result_test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 trees, # 50 depth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
